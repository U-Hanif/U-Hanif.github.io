---
title: "Research Intern"
company: "AMD Singapore"
date_start: "2025-07-01"
date_end: "2025-12-31"
---

Worked on optimizing LLM inference on AMD GPUs by profiling vLLM prefill/decode behavior, collecting analyzer-friendly traces, and studying how batching, input length, and KV-cache limits affect latency and concurrency. :contentReference[oaicite:4]{index=4}